{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_CNN_03.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYk44uj6GWQ0pegMis9OC6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ohFjQNopYEMN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Jk6eHcmBYRLx",
        "outputId": "7b177fa0-cc81-46b5-d1e0-4c3ee6bf737f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels),(test_images,test_labels)= mnist.load_data()"
      ],
      "metadata": {
        "id": "EJRkjXuFYTct"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "metadata": {
        "id": "y6EgKHjDY5v6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "# define the input shape, 64 filters of dimension 3 x 3\n",
        "model.add(Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "# maxpolling is done to compress the image and \n",
        "# enhance the feature of the image\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "# we can stack convolution layer on each other\n",
        "# and try to learn the very abstract feature\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(10,activation = 'softmax'))"
      ],
      "metadata": {
        "id": "tZ6pJ9Q6ZNtC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with this methodology, the network starts to learn based on the features of the image instead of just the raw patterns of the pixels"
      ],
      "metadata": {
        "id": "kngGh5Tvl0We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LjTy52FulpRw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images,train_labels,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqdk5O9FnIUo",
        "outputId": "7eab59c1-e82f-4043-c273-af909d101ad1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 90s 47ms/step - loss: 0.4370 - accuracy: 0.8426\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 85s 46ms/step - loss: 0.2894 - accuracy: 0.8938\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.2441 - accuracy: 0.9101\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 88s 47ms/step - loss: 0.2126 - accuracy: 0.9210\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 86s 46ms/step - loss: 0.1856 - accuracy: 0.9296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feabee59050>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification = model.predict(test_images)"
      ],
      "metadata": {
        "id": "hgq9uo17nRQX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkaQSy_cpth0",
        "outputId": "2262477a-5db3-4108-9880-a3a2c7398bce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2479364e-06, 2.2963961e-07, 1.3560108e-06, ..., 6.0869340e-04,\n",
              "        2.2799906e-05, 9.9921536e-01],\n",
              "       [4.2057427e-06, 4.4807816e-12, 9.9999440e-01, ..., 2.4642994e-14,\n",
              "        7.9619461e-10, 2.5773574e-14],\n",
              "       [1.6316415e-10, 1.0000000e+00, 1.5502277e-12, ..., 4.0781498e-15,\n",
              "        5.6068826e-12, 6.1663702e-16],\n",
              "       ...,\n",
              "       [3.1748586e-09, 9.9517562e-14, 3.3755287e-09, ..., 3.4833074e-11,\n",
              "        1.0000000e+00, 9.0057271e-15],\n",
              "       [5.3707084e-11, 1.0000000e+00, 9.3843661e-13, ..., 1.0946425e-14,\n",
              "        1.1285996e-11, 7.7007145e-15],\n",
              "       [4.2576069e-04, 1.5977137e-05, 1.6080964e-03, ..., 4.5988825e-01,\n",
              "        3.6704347e-01, 2.2086881e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ay1jhx2gpvOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}