{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day 69\n",
    "\n",
    "# Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While tokenizing allows you to identify words and sentences, **chunking** allows you to identify **phrases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<b>Note:</b> A <b>phrase</b> is a word or group of words that works as a single unit to perform a grammatical function. <b>Noun phrases</b> are built around a noun.\n",
    "\n",
    "Here are some examples:\n",
    "<ul>\n",
    "<li>“A planet”</li>\n",
    "<li>“A tilting planet”</li>\n",
    "<li>“A swiftly tilting planet”</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking makes use of POS tags to group words and apply chunk tags to those groups. Chunks don’t overlap, so one instance of a word can be in only one chunk at a time.\n",
    "\n",
    "Here’s how to import the relevant parts of NLTK in order to chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can chunk, you need to make sure that the parts of speech in your text are tagged, so create a string for POS tagging. You can use this quote from <a href = \"https://en.wikipedia.org/wiki/The_Lord_of_the_Rings\" >The Lord of the Rings</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_quote = \"It's a dangerous business, Frodo, going out your door.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tokenize that string by word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'dangerous',\n",
       " 'business',\n",
       " ',',\n",
       " 'Frodo',\n",
       " ',',\n",
       " 'going',\n",
       " 'out',\n",
       " 'your',\n",
       " 'door',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_lotr_quote = word_tokenize(lotr_quote)\n",
    "words_in_lotr_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you’ve got a list of all of the words in lotr_quote.\n",
    "\n",
    "The next step is to tag those words by part of speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('dangerous', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " (',', ','),\n",
       " ('Frodo', 'NNP'),\n",
       " (',', ','),\n",
       " ('going', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('your', 'PRP$'),\n",
       " ('door', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)\n",
    "lotr_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve got a list of tuples of all the words in the quote, along with their POS tag. In order to chunk, you first need to define a chunk grammar.\n",
    "\n",
    "**Note**: A **chunk grammar** is a combination of rules on how sentences should be chunked. It often uses <a href = \"https://realpython.com/regex-python/\"> regular expressions</a>, or **regexes**.\n",
    "\n",
    "For this tutorial, you don’t need to know how regular expressions work, but they will definitely <a href = \"https://xkcd.com/208/\"> come in handy</a> for you in the future if you want to process text.\n",
    "\n",
    "Create a chunk grammar with one regular expression rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NP stands for noun phrase. You can learn more about **noun phrase chunking** in <a href= \"https://www.nltk.org/book/ch07.html#noun-phrase-chunking\" > Chapter 7</a> of Natural Language Processing with Python—Analyzing Text with the Natural Language Toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the rule you created, your chunks:\n",
    "<ul>\n",
    "    \n",
    "<li>1.Start with an optional (?) determiner ('DT')</li>\n",
    "<li>2.Can have any number (*) of adjectives (JJ)</li>\n",
    "<li>3.End with a noun (&lt; NN>)</li>\n",
    "</ul> \n",
    "    \n",
    "Create a **chunk parser** with this grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar) # creating a parse/model with the grammar we made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chunk.RegexpParser with 1 stages>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try it out with your quote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = chunk_parser.parse(lotr_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how you can see a visual representation of this tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual representation we get the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You got two noun phrases:\n",
    "\n",
    "1.**'a dangerous business'** has a determiner, an adjective, and a noun.\n",
    "\n",
    "2.**'door'** has just a noun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2=\"the little yellow dog barked at the cat \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'little', 'yellow', 'dog', 'barked', 'at', 'the', 'cat']\n"
     ]
    }
   ],
   "source": [
    "# word tokkenise\n",
    "words=word_tokenize(sentence2)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# parts of speech\n",
    "pos_chunk = nltk.pos_tag(words)\n",
    "print(pos_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grammar\n",
    "\n",
    "# ? atleast 0 or 1 time\n",
    "# * is 0 or more times\n",
    "# ^ starts with\n",
    "grammar=(\"NP:{<DT>?<JJ>*<NN>}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkParser=nltk.RegexpParser(grammar) # RegexpParser is used to take the phrase using the help of grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chunk.RegexpParser with 1 stages>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n"
     ]
    }
   ],
   "source": [
    "t = chunkParser.parse(pos_chunk) #pass tagged words in the chucking parser\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
